{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d38c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mm_emb:  50%|█████     | 1/2 [00:29<00:29, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded #85 mm_emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mm_emb: 100%|██████████| 2/2 [00:36<00:00, 18.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded #86 mm_emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import MyDataset\n",
    "\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Train params\n",
    "    parser.add_argument('--batch_size', default=128, type=int)\n",
    "    parser.add_argument('--lr', default=0.001, type=float)\n",
    "    parser.add_argument('--maxlen', default=101, type=int)\n",
    "\n",
    "    # Baseline Model construction\n",
    "    parser.add_argument('--hidden_units', default=32, type=int)\n",
    "    parser.add_argument('--num_blocks', default=1, type=int)\n",
    "    parser.add_argument('--num_epochs', default=3, type=int)\n",
    "    parser.add_argument('--num_heads', default=1, type=int)\n",
    "    parser.add_argument('--dropout_rate', default=0.2, type=float)\n",
    "    parser.add_argument('--l2_emb', default=0.0, type=float)\n",
    "    parser.add_argument('--device', default='cpu', type=str)\n",
    "    parser.add_argument('--inference_only', action='store_true')\n",
    "    parser.add_argument('--state_dict_path', default=None, type=str)\n",
    "    parser.add_argument('--norm_first', action='store_true')\n",
    "\n",
    "    parser.add_argument('-f', '--file', default=None)  # 兼容Jupyter的自动参数\n",
    "    \n",
    "\n",
    "    # MMemb Feature ID\n",
    "    parser.add_argument('--mm_emb_id', nargs='+', default=['85','86'], type=str, choices=[str(s) for s in range(81, 87)]) #多模态\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "# global dataset\n",
    "data_path = '/Users/huang/Desktop/TX/dataset/TencentGR_1k'\n",
    "\n",
    "args = get_args()\n",
    "dataset = MyDataset(data_path, args)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [0.9, 0.1])\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0, collate_fn=dataset.collate_fn\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0, collate_fn=dataset.collate_fn\n",
    ")\n",
    "usernum, itemnum = dataset.usernum, dataset.itemnum\n",
    "feat_statistics, feat_types = dataset.feat_statistics, dataset.feature_types  #特征跟特征类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7cced5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1024,) into shape (3584,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m pos \u001b[38;5;241m=\u001b[39m pos\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     50\u001b[0m neg \u001b[38;5;241m=\u001b[39m neg\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 51\u001b[0m pos_logits, neg_logits, pos_pred \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     52\u001b[0m     seq, pos, neg, token_type, next_token_type, next_action_type, seq_feat, pos_feat, neg_feat\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/TX/v1/model.py:379\u001b[0m, in \u001b[0;36mBaselineModel.forward\u001b[0;34m(self, user_item, pos_seqs, neg_seqs, mask, next_mask, next_action_type, seq_feature, pos_feature, neg_feature)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m, user_item, pos_seqs, neg_seqs, mask, next_mask, next_action_type, seq_feature, pos_feature, neg_feature\n\u001b[1;32m    360\u001b[0m ):\n\u001b[1;32m    361\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    训练时调用，计算正负样本的logits\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m        neg_logits: 负样本logits，形状为 [batch_size, maxlen]\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     log_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog2feats(user_item, mask, seq_feature)\n\u001b[1;32m    380\u001b[0m     loss_mask \u001b[38;5;241m=\u001b[39m (next_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev)\n\u001b[1;32m    382\u001b[0m     pos_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat2emb(pos_seqs, pos_feature, include_user\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/TX/v1/model.py:331\u001b[0m, in \u001b[0;36mBaselineModel.log2feats\u001b[0;34m(self, log_seqs, mask, seq_feature)\u001b[0m\n\u001b[1;32m    329\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m log_seqs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    330\u001b[0m maxlen \u001b[38;5;241m=\u001b[39m log_seqs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 331\u001b[0m seqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat2emb(log_seqs, seq_feature, mask\u001b[38;5;241m=\u001b[39mmask, include_user\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    332\u001b[0m seqs \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_emb\u001b[38;5;241m.\u001b[39membedding_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    333\u001b[0m poss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, maxlen \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/Desktop/TX/v1/model.py:302\u001b[0m, in \u001b[0;36mBaselineModel.feat2emb\u001b[0;34m(self, seq, feature_array, mask, include_user)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seq):\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m item:\n\u001b[0;32m--> 302\u001b[0m             batch_emb_data[i, j] \u001b[38;5;241m=\u001b[39m item[k]\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# batch-convert and transfer to GPU\u001b[39;00m\n\u001b[1;32m    305\u001b[0m tensor_feature \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(batch_emb_data)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1024,) into shape (3584,)"
     ]
    }
   ],
   "source": [
    "args.device = 'cpu'\n",
    "from model import BaselineModel\n",
    "model = BaselineModel(usernum, itemnum, feat_statistics, feat_types, args).to(args.device)\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    try:\n",
    "        torch.nn.init.xavier_normal_(param.data)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "model.pos_emb.weight.data[0, :] = 0  #第0行置0\n",
    "model.item_emb.weight.data[0, :] = 0\n",
    "model.user_emb.weight.data[0, :] = 0\n",
    "\n",
    "for k in model.sparse_emb:\n",
    "    model.sparse_emb[k].weight.data[0, :] = 0\n",
    "\n",
    "epoch_start_idx = 1\n",
    "\n",
    "if args.state_dict_path is not None:\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(args.state_dict_path, map_location=torch.device(args.device)))\n",
    "        tail = args.state_dict_path[args.state_dict_path.find('epoch=') + 6 :]\n",
    "        epoch_start_idx = int(tail[: tail.find('.')]) + 1\n",
    "    except:\n",
    "        print('failed loading state_dicts, pls check file path: ', end=\"\")\n",
    "        print(args.state_dict_path)\n",
    "        raise RuntimeError('failed loading state_dicts, pls check file path!')\n",
    "\n",
    "bce_criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.98))\n",
    "\n",
    "best_val_ndcg, best_val_hr = 0.0, 0.0\n",
    "best_test_ndcg, best_test_hr = 0.0, 0.0\n",
    "T = 0.0\n",
    "t0 = time.time()\n",
    "global_step = 0\n",
    "print(\"Start training\")\n",
    "\n",
    "for epoch in range(epoch_start_idx, args.num_epochs + 1):\n",
    "    model.train()\n",
    "    if args.inference_only:\n",
    "        break\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        seq, pos, neg, token_type, next_token_type, next_action_type, seq_feat, pos_feat, neg_feat = batch\n",
    "        seq = seq.to(args.device)\n",
    "        pos = pos.to(args.device)\n",
    "        neg = neg.to(args.device)\n",
    "        pos_logits, neg_logits, pos_pred = model(\n",
    "            seq, pos, neg, token_type, next_token_type, next_action_type, seq_feat, pos_feat, neg_feat\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9761af02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
